# sglang Server (SGLang) 性能測試報告

## 測試環境
- **日期**: 2026年1月2日
- **GPU**: NVIDIA RTX 4060 Ti (8GB)
- **推論引擎**: SGLang (Docker Container)
- **模型**: Qwen/Qwen2.5-1.5B-Instruct
- **併發數**: 20 併發 (Concurrency)

---

## 1. 純文字生成基準測試 (Plain Text Chat)
模擬 20 個使用者同時請求模型撰寫短文。

| 指標 | 數值 | 說明 |
| :--- | :--- | :--- |
| **首字延遲 (Avg TTFT)** | **0.6033 s** | 從發送請求到收到第一個字的平均時間 |
| **平均總耗時** | **2.8188 s** | 每個請求完成生成的平均時間 |
| **系統總吞吐量** | **1815.07 tokens/s** | 伺服器每秒產出的總 Token 數 (極限效能) |
| **成功率** | **100% (40/40)** | 所有請求均正常回傳 |

---

## 2. 工具呼叫基準測試 (Tool / Function Calling)
模擬 20 個使用者同時請求帶有 `get_current_weather` 工具定義的任務。

| 指標 | 數值 | 說明 |
| :--- | :--- | :--- |
| **首字延遲 (Avg TTFT)** | **0.5907 s** | 模型解析工具定義並開始輸出的時間 |
| **平均總耗時** | **1.8207 s** | 生成 JSON 參數片段的總時間 |
| **系統總吞吐量** | **8.75 tokens/s** | 因 Tool Call 輸出極短，此數值主要反應處理頻率 |
| **成功率** | **100% (40/40)** | 所有 Tool Call 均正確觸發 |

---

## 3. 綜合分析與結論

### 🚀 SGLang 優勢分析
1. **極速反應 (Low Latency)**: 
   不論是純文字還是複雜的 Tool Use，首字反應時間 (TTFT) 均穩定在 **0.6 秒以下**。這對於即時對話應用（如語音助理、即時客服）非常理想。
   
2. **高效能結構化輸出**: 
   加入 `tools` 定義後，TTFT 並未增加（甚至微幅下降），顯示 SGLang 在處理 JSON Schema 引導生成時具有強大的優化，不會因為工具定義複雜而導致「思考」過久。

3. **高吞吐能力**: 
   在 1.5B 模型下，單張 4060 Ti 可達到 **1800+ tokens/s** 的驚人吞吐量，足以應對中大規模的內部併發需求。

### 💡 使用建議
- **Tool Use 場景**: 此伺服器非常適合用於「Agent」或「工具鏈」架構，處理 Tool Call 的開銷幾乎可以忽略不計。
- **擴展性**: 若未來需要處理更長文本，可調整 `docker-compose.sglang.yml` 中的 `context-length` 參數，但目前 8192 的設定在 8GB 顯存下運作良好。

---
*報告產生於：sglang-server 測試腳本*
