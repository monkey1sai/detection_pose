# SAGA ç¬¦è™Ÿå›æ­¸èª¿å„ª & UI å¢å¼·è¨­è¨ˆ

**Date**: 2026-01-26  
**Author**: Brainstorming Session  
**Status**: Approved

## Objective

è®“ SAGA åœ¨ä½¿ç”¨æœ¬åœ° **Qwen 2.5 7B (Q4_K_M)** æ¨¡å‹æ™‚ï¼Œèƒ½å¤ æ­£ç¢ºæ‰¾åˆ°ç¬¦è™Ÿå›æ­¸å•é¡Œçš„è§£ã€‚

**æ¸¬è©¦é¡Œç›®**ï¼š
- æ•¸æ“šé»: `[(-3,-2),(-2,-4),(-1,-4),(0,-2),(1,2),(2,8),(3,16),(4,26)]`
- æ­£è§£: `y = xÂ² + 3x - 2`

---

## å•é¡Œè¨ºæ–·

å¾ç”¨æˆ¶æˆªåœ–è§€å¯Ÿåˆ°ï¼š
1. è¼¸å‡º `x**2-x x) + x` â†’ èªæ³•éŒ¯èª¤ï¼Œéåˆæ³•å…¬å¼
2. åˆ†æ•¸ 0.1504 â†’ æ¥µä½ï¼Œæ“¬åˆæ•ˆæœå·®
3. çµ‚æ­¢åŸå›  `Score converged (eps=0.01)` â†’ éæ—©æ”¶æ–‚

**æ ¹æœ¬åŸå› **ï¼šæœç´¢ç­–ç•¥éæ–¼ä¿å®ˆï¼Œå…§éƒ¨è¿­ä»£æ¬¡æ•¸ä¸è¶³ï¼Œæ”¶æ–‚åˆ¤å®šéæ–¼å¯¬é¬†ã€‚

---

## Proposed Changes

### 1. æœç´¢ç­–ç•¥å„ªåŒ–ï¼ˆæ¿€é€²æ¨¡å¼ï¼‰

#### 1.1 å¾Œç«¯åƒæ•¸ (`saga/runner.py`)

| åƒæ•¸ | åŸå€¼ | æ–°å€¼ | ä½ç½® |
|------|------|------|------|
| `inner_iterations` | 6 | **15** | L155 |
| `batch_size` | 10 | **20** | L156 |

#### 1.2 å‰ç«¯é è¨­æ¨¡æ¿ (`web_client/src/App.jsx`)

```javascript
symbolic_regression: {
  name: "ç¬¦è™Ÿå›æ­¸ (Symbolic Regression)",
  maxIters: 20,           // åŸ: 5
  convergenceEps: 0.001,  // åŸ: 0.01
  patience: 5,            // åŸ: 2
  weights: "0.85, 0.1, 0.05",  // åŸ: 0.5, 0.3, 0.2 (ç´”ç²¹è¿½æ±‚æ“¬åˆ)
}
```

#### 1.3 LLM å–æ¨£åƒæ•¸ (`.env`)

| åƒæ•¸ | åŸå€¼ | æ–°å€¼ | ç†ç”± |
|------|------|------|------|
| `SGLANG_TEMPERATURE` | 0.6 | **0.4** | æ›´ç©©å®šçš„æ•¸å­¸è¡¨é”å¼ |
| `SGLANG_TOP_K` | 20 | **10** | æ¸›å°‘éš¨æ©Ÿæ€§ |

---

### 2. UI å¯è¦–åŒ–å¢å¼·

#### 2.1 æ–°å¢ LLM äº‹ä»¶é¡å‹

åœ¨ `saga/search/generators.py` çš„ `LLMGenerator.generate()` ä¸­ç™¼é€äº‹ä»¶ï¼š

```python
# Request äº‹ä»¶
{
  "type": "llm_request",
  "prompt_preview": "...(å‰200å­—)...",
  "iteration": 3,
  "timestamp": 1706234567.89
}

# Response äº‹ä»¶
{
  "type": "llm_response",
  "raw_preview": "...(å‰300å­—)...",
  "parsed_candidates": ["x**2 + 3*x - 2", ...],
  "filtered_count": 2,
  "accepted_count": 5
}
```

#### 2.2 äº‹ä»¶é™¤éŒ¯æ ¼å¼åŒ–

å°‡ã€Œäº‹ä»¶é™¤éŒ¯ã€é¢æ¿çš„ JSON æ”¹ç‚ºå¯å±•é–‹çš„æ¨¹ç‹€çµæ§‹ï¼š

- ä½¿ç”¨ `react-json-view` æˆ–é¡ä¼¼çµ„ä»¶
- æ¯å€‹äº‹ä»¶å¯é»æ“Šå±•é–‹
- æ ¹æ“š `type` é¡¯ç¤ºä¸åŒé¡è‰²åœ–æ¨™

#### 2.3 é¡è‰²å€åˆ†

| äº‹ä»¶é¡å‹ | é¡è‰² | åœ–æ¨™ |
|----------|------|------|
| `system_log` | ç°è‰² | ğŸ“ |
| `llm_request` | è—è‰² | ğŸ”µ |
| `llm_response` | ç¶ è‰² | ğŸŸ¢ |
| `error` | ç´…è‰² | ğŸ”´ |
| `iteration_update` | é»ƒè‰² | ğŸ”„ |

---

### 3. é‹ç®—åœ–åŠŸèƒ½å¯¦ç¾

#### 3.1 ç”¢ç”Ÿæ™‚æ©Ÿ

åœ¨ `saga/outer_loop.py` çš„ `run()` çµæŸæ™‚å‘¼å«ï¼š

```python
from saga.trace.graph import write_graph, write_mermaid

# åœ¨ yield FinalReport ä¹‹å‰
nodes = [{"id": f"Iter_{i}", "label": f"Iteration {i}", "score": s} 
         for i, s in enumerate(state.score_history, 1)]
edges = [{"from": f"Iter_{i}", "to": f"Iter_{i+1}"} 
         for i in range(1, len(nodes))]

run_dir = self.config.run_path(run_id)
write_graph(run_dir / "graph.json", nodes, edges)
write_mermaid(run_dir / "workflow.mmd", edges)
```

#### 3.2 Mermaid è¼¸å‡ºç¯„ä¾‹

```mermaid
graph TD
Iter_1 --> Iter_2
Iter_2 --> Iter_3
Iter_3 --> Iter_4
```

---

## Verification Plan

### è‡ªå‹•æ¸¬è©¦
```bash
# é‡å»ºæœå‹™
docker compose up -d --build saga_server web

# æ‰‹å‹•æ¸¬è©¦ç¬¦è™Ÿå›æ­¸
# åœ¨ UI ä¸Šé¸æ“‡ã€Œç¬¦è™Ÿå›æ­¸ã€æ¨¡æ¿ï¼ŒåŸ·è¡Œå¾Œè§€å¯Ÿï¼š
# 1. æ˜¯å¦èƒ½æ‰¾åˆ°æ¥è¿‘ x**2 + 3*x - 2 çš„å…¬å¼
# 2. åˆ†æ•¸æ˜¯å¦æ¥è¿‘ 1.0
# 3. LLM æ—¥èªŒæ˜¯å¦æ­£å¸¸é¡¯ç¤º
# 4. é‹ç®—åœ–æ˜¯å¦æ­£å¸¸æ¸²æŸ“
```

### æˆåŠŸæ¨™æº–
- [ ] å…¬å¼ `x**2 + 3*x - 2` æˆ–ç­‰åƒ¹å½¢å¼å‡ºç¾åœ¨å€™é¸ä¸­
- [ ] æœ€çµ‚åˆ†æ•¸ â‰¥ 0.95
- [ ] UI é¡¯ç¤º LLM è¼¸å…¥/è¼¸å‡ºæ—¥èªŒ
- [ ] é‹ç®—åœ–æ­£ç¢ºé¡¯ç¤ºè¿­ä»£æµç¨‹

---

## Files to Modify

| æª”æ¡ˆ | ä¿®æ”¹å…§å®¹ |
|------|----------|
| `saga/runner.py` | èª¿æ•´ `inner_iterations`, `batch_size` |
| `saga/outer_loop.py` | æ·»åŠ  `write_graph` / `write_mermaid` å‘¼å« |
| `saga/search/generators.py` | æ·»åŠ  LLM äº‹ä»¶ç™¼é€ï¼ˆéœ€ WebSocket callbackï¼‰ |
| `web_client/src/App.jsx` | æ›´æ–°æ¨¡æ¿é è¨­å€¼ã€äº‹ä»¶æ ¼å¼åŒ– UI |
| `.env` | èª¿æ•´ `SGLANG_TEMPERATURE`, `SGLANG_TOP_K` |
